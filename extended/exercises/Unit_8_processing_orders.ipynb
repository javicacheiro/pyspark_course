{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the required topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we are using the `curso800` account, let's start by creating `orders.curso800` and `manufacturing.curso800` topics in kafka. \n",
    "\n",
    "The first topic will receive the customer orders from the producer script and the second topic will be where the streaming app will generate the manufacturing orders.\n",
    "\n",
    "```bash\n",
    "module load kafka\n",
    "\n",
    "export BROKER=\"10.133.29.20:9092\"\n",
    "\n",
    "kafka-topics.sh --bootstrap-server $BROKER --topic orders.curso800 --create --partitions 1 --replication-factor 1\n",
    "\n",
    "kafka-topics.sh --bootstrap-server $BROKER --topic manufacturing.curso800 --create --partitions 1 --replication-factor 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the consumer app code and launch it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the consumer app code: [Unit_8_processing_orders_lab.py](exercises/Unit_8_processing_orders_lab.py)\n",
    "\n",
    "**Update the topic names from `orders.curso800` and `manufacturing.curso800` to the appropriate values.**\n",
    "\n",
    "Remove the checkpoint dir\n",
    "Launch the app:\n",
    "\n",
    "- Option 1: Using Spark 3.4.3:\n",
    "\n",
    "```bash\n",
    "module load spark/3.4.3\n",
    "export BROKER=\"<broker_ip_address>:9092\"\n",
    "\n",
    "# Remove previous checkpoint dir (in case it exists)\n",
    "hdfs dfs -rm -r -f orders_checkpoint_dir\n",
    "\n",
    "spark-submit --conf spark.dynamicAllocation.enabled=false --num-executors 2 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.3 Unit_8_processing_orders_lab.py\n",
    "```\n",
    "\n",
    "\n",
    "- Option 2: Using Spark 2.4.0:\n",
    "\n",
    "```bash\n",
    "export BROKER=\"<broker_ip_address>:9092\"\n",
    "\n",
    "# Remove previous checkpoint dir (in case it exists)\n",
    "hdfs dfs -rm -r -f orders_checkpoint_dir\n",
    "\n",
    "spark-submit --conf spark.dynamicAllocation.enabled=false --num-executors 2 --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0 Unit_8_processing_orders_lab.py\n",
    "```\n",
    "\n",
    "NOTE: It is important to **remove the previous checkpoint dir** (in case it exists) if you modify the app or if you want to restart from the beginning. In other case you will get strange error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the producer code and launch it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the producer code: [Unit_8_orders_producer_kafka-python.py](exercises/Unit_8_orders_producer_kafka-python.py)\n",
    "\n",
    "As you can see it is a standalone python program that uses `kafka-python`.\n",
    "\n",
    "**Update the topic name from `orders.curso800` to the appropriate value.**\n",
    "\n",
    "\n",
    "Launch the producer script:\n",
    "```bash\n",
    "module load anaconda3/2024.02-1\n",
    "python Unit_8_orders_producer_kafka-python.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how new manufacturing orders are generated in real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a console consumer we will now see how new producing orders are being generated by the streaming app and send to the `manufacturing.curso800` topic:\n",
    "\n",
    "```bash\n",
    "module load kafka\n",
    "export BROKER=\"10.133.29.20:9092\"\n",
    "export TOPIC=\"manufacturing.curso800\"\n",
    "kafka-console-consumer.sh --bootstrap-server $BROKER --topic $TOPIC --from-beginning\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
