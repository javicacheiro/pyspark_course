{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter: Developing the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `read` method instead of the `readStream` method. This way we will be able to create a static dataframe from the Kafka data stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, expr, to_json, window, expr, to_timestamp\n",
    "from  pyspark.sql.types import StructType, StructField, LongType, StringType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"created_at\", StringType()),\n",
    "    StructField(\"lang\", StringType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "])\n",
    "\n",
    "raw = spark.read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"10.38.28.103:9092\") \\\n",
    "    .option(\"subscribe\", \"twitter\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tests let's keep only 5 rows of the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_subset = raw.limit(5)\n",
    "raw_subset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform the stream adding a column with the partition id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = raw_subset.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value=Row(created_at=u'2022-09-24T19:24:22.000Z', lang=u'en', text=u\"RT @dewaleism: It's unimaginable to see that these Iranian women have more balls that those Russian men fleeing Putin's #mobilization. You\\u2026\")),\n",
       " Row(value=Row(created_at=u'2022-09-24T19:24:23.000Z', lang=u'en', text=u'@AndrewDevoss @TulsiGabbard Brandon says, \"F*** the American people\". https://t.co/TzWyOPje7A')),\n",
       " Row(value=Row(created_at=u'2022-09-24T19:24:23.000Z', lang=u'en', text=u'@Zzzaikar Putin is murdering his own citizens. These are young people, with little military experience, being sent to fight a war that serves ONLY to enrich mafia Putin and his corrupted mates #PutinWarCriminal')),\n",
       " Row(value=Row(created_at=u'2022-09-24T19:24:24.000Z', lang=u'en', text=u'Because of Fascist-supporting, Putin apologist Tankies like you.\\n\\nPerhaps he needs the number for Wagner so he can sign up? https://t.co/W6keQhl9RJ')),\n",
       " Row(value=Row(created_at=u'2022-09-24T19:24:26.000Z', lang=u'en', text=u'RT @DrDenaGrayson: \\U0001f6a8BREAKNG: Drafted men in Omsk, #Russia are fighting police to avoid being forced into military service, telling the cops\\u2026'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = values.selectExpr(\"value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_at=u'2022-09-24T19:24:22.000Z', lang=u'en', text=u\"RT @dewaleism: It's unimaginable to see that these Iranian women have more balls that those Russian men fleeing Putin's #mobilization. You\\u2026\"),\n",
       " Row(created_at=u'2022-09-24T19:24:23.000Z', lang=u'en', text=u'@AndrewDevoss @TulsiGabbard Brandon says, \"F*** the American people\". https://t.co/TzWyOPje7A'),\n",
       " Row(created_at=u'2022-09-24T19:24:23.000Z', lang=u'en', text=u'@Zzzaikar Putin is murdering his own citizens. These are young people, with little military experience, being sent to fight a war that serves ONLY to enrich mafia Putin and his corrupted mates #PutinWarCriminal'),\n",
       " Row(created_at=u'2022-09-24T19:24:24.000Z', lang=u'en', text=u'Because of Fascist-supporting, Putin apologist Tankies like you.\\n\\nPerhaps he needs the number for Wagner so he can sign up? https://t.co/W6keQhl9RJ'),\n",
       " Row(created_at=u'2022-09-24T19:24:26.000Z', lang=u'en', text=u'RT @DrDenaGrayson: \\U0001f6a8BREAKNG: Drafted men in Omsk, #Russia are fighting police to avoid being forced into military service, telling the cops\\u2026')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have to parse the date string.**\n",
    "\n",
    "Here we have the reference for the pattern syntax:\n",
    "- [Datetime Patterns for Formatting and Parsing](https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some tests to see if we are able to parse it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The automatic mode seems to recognize the format correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|to_timestamp('2022-09-24T19:24:22.000Z')|\n",
      "+----------------------------------------+\n",
      "|                     2022-09-24 21:24:22|\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select to_timestamp(\"2022-09-24T19:24:22.000Z\")''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the doc and creating a specific string pattern does not seem to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "|to_timestamp('2022-09-24T19:24:22.000Z', 'yyyy-MM-ddTHH:mm:ss.SSSZ')|\n",
      "+--------------------------------------------------------------------+\n",
      "|                                                                null|\n",
      "+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select to_timestamp(\"2022-09-24T19:24:22.000Z\", \"yyyy-MM-ddTHH:mm:ss.SSSZ\")''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem is that we have to use the `'` character to escape text (see the reference above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+\n",
      "|to_timestamp('2022-09-24T19:24:22.000Z', 'yyyy-MM-dd\\'T\\'HH:mm:ss')|\n",
      "+-------------------------------------------------------------------+\n",
      "|                                                2022-09-24 19:24:22|\n",
      "+-------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select to_timestamp(\"2022-09-24T19:24:22.000Z\", \"yyyy-MM-dd'T'HH:mm:ss\")''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = exploded.withColumn(\n",
    "    \"created_at\",\n",
    "    to_timestamp(col(\"created_at\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_at=datetime.datetime(2022, 9, 24, 19, 24, 22), lang=u'en', text=u\"RT @dewaleism: It's unimaginable to see that these Iranian women have more balls that those Russian men fleeing Putin's #mobilization. You\\u2026\"),\n",
       " Row(created_at=datetime.datetime(2022, 9, 24, 19, 24, 23), lang=u'en', text=u'@AndrewDevoss @TulsiGabbard Brandon says, \"F*** the American people\". https://t.co/TzWyOPje7A'),\n",
       " Row(created_at=datetime.datetime(2022, 9, 24, 19, 24, 23), lang=u'en', text=u'@Zzzaikar Putin is murdering his own citizens. These are young people, with little military experience, being sent to fight a war that serves ONLY to enrich mafia Putin and his corrupted mates #PutinWarCriminal'),\n",
       " Row(created_at=datetime.datetime(2022, 9, 24, 19, 24, 24), lang=u'en', text=u'Because of Fascist-supporting, Putin apologist Tankies like you.\\n\\nPerhaps he needs the number for Wagner so he can sign up? https://t.co/W6keQhl9RJ'),\n",
       " Row(created_at=datetime.datetime(2022, 9, 24, 19, 24, 26), lang=u'en', text=u'RT @DrDenaGrayson: \\U0001f6a8BREAKNG: Drafted men in Omsk, #Russia are fighting police to avoid being forced into military service, telling the cops\\u2026')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumbling_window = tweets.groupBy(\n",
    "    window(col(\"created_at\"), \"5 minutes\")\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|[2022-09-24 19:20:00, 2022-09-24 19:25:00]|5    |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tumbling_window.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "my_saved_model = PipelineModel.load('models/amazon_sentiment_analysis_cv_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df = tweets.withColumn('reviewText', col('text')).withColumn('overall', lit(5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_saved_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text       | RT @dewaleism: It's unimaginable to see that these Iranian women have more balls that those Russian men fleeing Putin's #mobilization. Youâ€¦                      \n",
      " prediction | 1.0                                                                                                                                                              \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text       | @AndrewDevoss @TulsiGabbard Brandon says, \"F*** the American people\". https://t.co/TzWyOPje7A                                                                    \n",
      " prediction | 1.0                                                                                                                                                              \n",
      "-RECORD 2----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text       | @Zzzaikar Putin is murdering his own citizens. These are young people, with little military experience, being sent to fight a war that serves ONLY to enrich ... \n",
      " prediction | 1.0                                                                                                                                                              \n",
      "-RECORD 3----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text       | Because of Fascist-supporting, Putin apologist Tankies like you.\n",
      "\n",
      "Perhaps he needs the number for Wagner so he can sign up? https://t.co/W6keQhl9RJ              \n",
      " prediction | 1.0                                                                                                                                                              \n",
      "-RECORD 4----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " text       | RT @DrDenaGrayson: ðŸš¨BREAKNG: Drafted men in Omsk, #Russia are fighting police to avoid being forced into military service, telling the copsâ€¦                    \n",
      " prediction | 1.0                                                                                                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('text', 'prediction').show(vertical=True, truncate=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remember the 1.0 meant possitive sentiment and the 0.0 negative (look at amazon lab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use TextBlob you will have to install it first using:\n",
    "```\n",
    "pip install --user TextBlob\n",
    "```\n",
    "\n",
    "and then you have to download corpora:\n",
    "```\n",
    "python -m textblob.download_corpora\n",
    "```\n",
    "\n",
    "To use in a spark job we will have to generate a zip with the dependencies:\n",
    "```\n",
    "pip install -t dependencies -r requirements_textblob.txt\n",
    "cd dependencies\n",
    "zip -r ../dependencies.zip .\n",
    "```\n",
    "\n",
    "And then to include the dependencies you will use the `--py-files dependencies.zip` option.\n",
    "\n",
    "Additionaly we will need the `corpus` stored in `/opt/cesga/nltk_data`:\n",
    "```\n",
    "export NLTK_DATA=\"/opt/cesga/nltk_data\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use TextBlob:\n",
    "- [TextBlob: Simplified Text Processing](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n",
      "-0.341666666667\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from textblob import TextBlob\n",
    "\n",
    "text = \"\"\"\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "\"\"\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"This is wonderful.\"), Sentence(\"Just wonderful.\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('This is wonderful. Just wonderful.').sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.polarity for s in TextBlob('This is wonderful. Just wonderful.').sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([s.polarity for s in TextBlob('This is wonderful. Just wonderful.').sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pyspark to test TextBlob interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will save our tweets dataframe in HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.write.parquet('tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that TextBlob works in the cluster we would have to use `pyspark` instead of `jupyter`:\n",
    "- We have to pass as `py-files` our `dependencies.zip`\n",
    "- We have to set the `NLTK_DATA` environmental variable\n",
    "\n",
    "```\n",
    "PYSPARK_PYTHON=$(which python) PYSPARK_DRIVER_PYTHON=$(which ipython) pyspark \\\n",
    "    --py-files notebook/extended/exercises/dependencies.zip \\\n",
    "    --conf spark.executorEnv.NLTK_DATA=\"/opt/cesga/nltk_data\"\n",
    "```\n",
    "\n",
    "Let's verify that the TextBlob module is available in the executors (run this inside the `pyspark` session you have just launched):\n",
    "```python\n",
    "sc.parallelize(range(2), 2).map(lambda x: TextBlob('Wonderful')).collect()\n",
    "```\n",
    "\n",
    "To use with the Spark Structured API we have to define a UDF function first:\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from textblob import TextBlob\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def polarity(text):\n",
    "    return sum([s.polarity for s in TextBlob(text).sentences])\n",
    "```\n",
    "\n",
    "And then we can test the UDF function in pyspark:\n",
    "```python\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "tweets = spark.read.parquet('tweets')\n",
    "tweets.show()\n",
    "\n",
    "df = (tweets\n",
    "      .withColumn('polarity', polarity(col('text')))\n",
    "     )\n",
    "df.select('text', 'polarity').show(vertical=True, truncate=160)\n",
    "```\n",
    "\n",
    "We can also test TextBlob in a given tweet (we will see that the polarity returned is usually 0):\n",
    "```python\n",
    "[s.polarity for s in TextBlob(u'RT @DrDenaGrayson: ðŸš¨BREAKNG: Drafted men in Omsk, #Russia are fighting police to avoid being forced into military service, telling the copsâ€¦').sentences]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to go and we can proceed with our app.\n",
    "\n",
    "To submit it to the cluster you can use:\n",
    "\n",
    "```\n",
    "spark-submit --conf spark.dynamicAllocation.enabled=false --num-executors 2 Unit_8_twitter_sentiment_analysis.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
